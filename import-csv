#!/usr/bin/env python

import os
import re
import csv
import sys
import decimal
import datetime
import argparse

from sqlalchemy import create_engine, MetaData, Text, Integer, Numeric, \
                       DateTime, BigInteger
from sqlalchemy.orm import sessionmaker
from sqlalchemy.schema import Table, Column


parser = argparse.ArgumentParser()
parser.add_argument("--url", "-u", help="sqlalchemy url", required=True)
parser.add_argument("--file", "-f", help="csv file", required=True)
parser.add_argument("--table", "-t", help="table name", default=None)
parser.add_argument("--delimiter", help="csv delimiter", default=",")
parser.add_argument("--integer", "-i", help="integer columns",
                    action="store_true", default=False)
parser.add_argument("--numeric", "-n", help="numeric parsing",
                    action="store_true", default=False)
parser.add_argument("--timestamp", "-p", help="timestamp parsing",
                    action="store_true", default=False)
parser.add_argument("--mogrify", "-m", help="clean names",
                    action="store_true", default=True)
parser.add_argument("--lower", "-l", help="lowercase names",
                    action="store_true", default=False)
parser.add_argument("--drop", "-d", help="drop table first",
                    action="store_true", default=False)
parser.add_argument("--empty-nulls", "-e", help="empty fields are null",
                    action="store_true", default=False)
parser.add_argument("--skip-parsing", "-s", help="skip type parsing for cols")
parser.add_argument("--big-integer", "-b", help="use bigint instead of int",
                    default=False, action="store_true")

args = parser.parse_args()

# check that our given file exists
if (not args.file or not os.path.exists(args.file)) and args.file != "-":
    sys.stderr.write("file '{}' does not exist.\n".format(args.file))
    sys.exit(1)

# check that we've been given a table name if - was our file
if args.file == "-" and not args.table:
    sys.stderr.write("standard input requested, but no table name given.\n")
    sys.exit(1)

# name cleaner function
empties = ""
def clean_name(name):
    global empties
    name = re.sub(r'[^a-zA-Z0-9_]', "_", name)
    name = re.sub(r'_+', "_", name)
    if args.lower:
        name = name.lower()
    if not name:
        empties += "_"
        name = empties
    return name

# construct a table name from the file name
if args.table is None:
    path_parts = os.path.split(args.file)
    file_name = path_parts[1]

    pieces = file_name.split(".")
    if len(pieces) > 1:
        pieces = pieces[:-1]

    table_name = ".".join(pieces)

    if args.mogrify:
        table_name = clean_name(table_name)
else:
    table_name = args.table

# determine any columns we should not type parse
skip_type_parsing = []
if args.skip_parsing:
    cols = args.skip_parsing.split(",")
    skip_type_parsing = [c.strip() for c in cols]

# hook up with our database
engine = create_engine(args.url)
session = sessionmaker(bind=engine)()
metadata = MetaData()

# get a handle on things
if args.file == "-":
    fp = sys.stdin
else:
    fp = open(args.file)


# try and figure out the type of the given value
def get_type(value, args):
    # date formats will be crossed with time formats
    date_formats = [
        "%Y-%m-%d",
        "%Y%m%d",
        "%m/%d/%Y",
        "%b %d, %Y",
    ]

    time_formats = [
        "%H:%M:%S",
        "%H:%M:%S %z",
        "%H:%M:%S %Z",
        "%I:%M:%S %p",
        "%I:%M:%S %P",
    ]

    datetime_formats = []
    for date_format in date_formats:
        datetime_formats.append(date_format)
        for time_format in time_formats:
            datetime_formats.append(date_format + " " + time_format)
            datetime_formats.append(date_format + "T" + time_format)

    # first the timestamp
    if args.timestamp:
        for timestamp_format in datetime_formats:
            try:
                datetime.datetime.strptime(value, timestamp_format)
                if not (len(value) != 8 and timestamp_format == "%Y%m%d"):
                    return DateTime
            except ValueError:
                pass

    # then integers
    if args.integer:
        try:
            int(value)
            if args.big_integer:
                return BigInteger
            else:
                return Integer
        except ValueError:
            pass

    # then numeric
    if args.numeric:
        try:
            decimal.Decimal(value)
            return Numeric
        except decimal.InvalidOperation:
            pass
    
    # we got nothing
    return Text


# start processing the file
first = True
table = None
header_mapping = {}
for record in csv.DictReader(fp, delimiter=args.delimiter):

    # on the first iteration, map our headers to new names if requested and
    # drop and create our table
    if first:
        fields = record.keys()

        if args.mogrify:
            for field in fields:
                header_mapping[field] = clean_name(field)
        else:
            header_mapping = {f:f for f in fields}

        # sort them in the order of our (new?) names
        fields = sorted(fields, key=lambda k: header_mapping[k])

        # build a table with some hopefully reasonable types
        columns = []
        for field in fields:
            value = record[field]

            # typed columns (with maybe nice names)
            if field in skip_type_parsing \
                    or header_mapping[field] in skip_type_parsing:
                column_type = Text
            else:
                column_type = get_type(value, args)
            column = Column(header_mapping[field], column_type)
            columns.append(column)

        # construct our table object
        table = Table(table_name, metadata, *columns)

        # drop on request
        if args.drop:
            table.drop(bind=session.bind, checkfirst=True)

        # create. this could fail if you aren't paying attention
        table.create(bind=session.bind)

        # enough of this boring crap
        first = False

    # empty fields become None
    if args.empty_nulls:
        record = {k: v if v else None for k, v in record.items()}

    # create our insert values
    if args.mogrify:
        mapped_record = {header_mapping[f]: v for f, v in record.items()}
    else:
        mapped_record = record

    # do the needful
    session.execute(table.insert(), mapped_record)

# save
session.commit()
